{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Preprocessing is a crucial step in Natural Language Processing. It includes tasks like stop word removal and stemming to convert raw text into a more useful and structured form. These processes help in reducing the complexity of the text data by eliminating common but insignificant words (stop words) and reducing words to their base or root forms (stemming). This enables machine learning models to focus on the most meaningful aspects of the data, improving performance and accuracy in tasks such as text classification, sentiment analysis, and information retrieval. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop word removal \n",
    "text = text.lower()\n",
    "text_tokens = word_tokenize(text)  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "filtered = ' '.join([word for word in text_tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: preprocessing is a crucial step in natural language processing. it includes tasks like stop word removal and stemming to convert raw text into a more useful and structured form. these processes help in reducing the complexity of the text data by eliminating common but insignificant words (stop words) and reducing words to their base or root forms (stemming). this enables machine learning models to focus on the most meaningful aspects of the data, improving performance and accuracy in tasks such as text classification, sentiment analysis, and information retrieval. \n",
      "\n",
      "Filtered text: preprocessing crucial step natural language processing . includes tasks like stop word removal stemming convert raw text useful structured form . processes help reducing complexity text data eliminating common insignificant words ( stop words ) reducing words base root forms ( stemming ) . enables machine learning models focus meaningful aspects data , improving performance accuracy tasks text classification , sentiment analysis , information retrieval .\n",
      "Stemmed text: preprocess crucial step natur languag process . includ task like stop word remov stem convert raw text use structur form . process help reduc complex text data elimin common insignific word ( stop word ) reduc word base root form ( stem ) . enabl machin learn model focu meaning aspect data , improv perform accuraci task text classif , sentiment analysi , inform retriev .\n",
      "Lemmatized text: preprocessing crucial step natural language processing . includes task like stop word removal stemming convert raw text useful structured form . process help reducing complexity text data eliminating common insignificant word ( stop word ) reducing word base root form ( stemming ) . enables machine learning model focus meaningful aspect data , improving performance accuracy task text classification , sentiment analysis , information retrieval .\n"
     ]
    }
   ],
   "source": [
    "# stemming of the words \n",
    "\n",
    "stemmr = PorterStemmer()\n",
    "\n",
    "\n",
    "stemmed_text = ' '.join([stemmr.stem(word) for word in filtered.split()]) \n",
    "\n",
    "# lemmatization of the words\n",
    "\n",
    "lemmatizr = WordNetLemmatizer() \n",
    "\n",
    "lemmatized = ' '.join([lemmatizr.lemmatize(word) for word in filtered.split()]) \n",
    "\n",
    "\n",
    "print(f'Original text: {text}')\n",
    "print(f'Filtered text: {filtered}')\n",
    "print(f'Stemmed text: {stemmed_text}')\n",
    "print(f'Lemmatized text: {lemmatized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('preprocessing', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('crucial', 'JJ'), ('step', 'NN'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('.', '.'), ('it', 'PRP'), ('includes', 'VBZ'), ('tasks', 'NNS'), ('like', 'IN'), ('stop', 'NN'), ('word', 'NN'), ('removal', 'NN'), ('and', 'CC'), ('stemming', 'VBG'), ('to', 'TO'), ('convert', 'VB'), ('raw', 'JJ'), ('text', 'NN'), ('into', 'IN'), ('a', 'DT'), ('more', 'RBR'), ('useful', 'JJ'), ('and', 'CC'), ('structured', 'JJ'), ('form', 'NN'), ('.', '.'), ('these', 'DT'), ('processes', 'NNS'), ('help', 'VBP'), ('in', 'IN'), ('reducing', 'VBG'), ('the', 'DT'), ('complexity', 'NN'), ('of', 'IN'), ('the', 'DT'), ('text', 'NN'), ('data', 'NNS'), ('by', 'IN'), ('eliminating', 'VBG'), ('common', 'JJ'), ('but', 'CC'), ('insignificant', 'JJ'), ('words', 'NNS'), ('(', '('), ('stop', 'VB'), ('words', 'NNS'), (')', ')'), ('and', 'CC'), ('reducing', 'VBG'), ('words', 'NNS'), ('to', 'TO'), ('their', 'PRP$'), ('base', 'NN'), ('or', 'CC'), ('root', 'NN'), ('forms', 'NNS'), ('(', '('), ('stemming', 'VBG'), (')', ')'), ('.', '.'), ('this', 'DT'), ('enables', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('models', 'NNS'), ('to', 'TO'), ('focus', 'VB'), ('on', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('meaningful', 'JJ'), ('aspects', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('data', 'NNS'), (',', ','), ('improving', 'VBG'), ('performance', 'NN'), ('and', 'CC'), ('accuracy', 'NN'), ('in', 'IN'), ('tasks', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('text', 'JJ'), ('classification', 'NN'), (',', ','), ('sentiment', 'NN'), ('analysis', 'NN'), (',', ','), ('and', 'CC'), ('information', 'NN'), ('retrieval', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos = pos_tag(word_tokenize(text)) \n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
